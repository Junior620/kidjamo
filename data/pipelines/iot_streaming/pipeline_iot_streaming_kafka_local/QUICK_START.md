# ğŸš€ Guide de DÃ©marrage Rapide - Pipeline IoT Streaming Kidjamo

## Vue d'ensemble

Cette pipeline simule et traite en temps rÃ©el les donnÃ©es de bracelets mÃ©dicaux IoT pour le suivi de patients drÃ©panocytaires.

```
ğŸ“± Bracelets SimulÃ©s â†’ ğŸŒ API FastAPI â†’ ğŸ“Š Kafka â†’ âš¡ PySpark â†’ ğŸ’¾ Data Lake Local
```

## âš¡ DÃ©marrage Express (5 minutes)

### 1. PrÃ©requis
```bash
# VÃ©rifier Docker
docker --version
docker-compose --version

# VÃ©rifier Python
python --version  # 3.8+
```

### 2. Installation
```bash
# Cloner et naviguer
cd pipeline_iot_streaming_kafka_local

# Windows
.\start_pipeline.ps1 -WithSimulator

# Linux/Mac
chmod +x start_pipeline.sh
./start_pipeline.sh --with-simulator
```

### 3. VÃ©rification
- **API**: http://localhost:8001/docs
- **Kafka UI**: http://localhost:8090
- **SantÃ©**: http://localhost:8001/health

---

## ğŸ“Š Points d'accÃ¨s

| Service | URL | Description |
|---------|-----|-------------|
| **API Documentation** | http://localhost:8001/docs | Interface Swagger |
| **API Health** | http://localhost:8001/health | Statut systÃ¨me |
| **Kafka UI** | http://localhost:8090 | Interface Kafka |
| **Monitoring** | `streamlit run monitoring/realtime_dashboard.py` | Dashboard temps rÃ©el |

---

## ğŸ”„ Workflow de dÃ©veloppement

### Cycle normal
```bash
# 1. DÃ©marrer la pipeline
.\start_pipeline.ps1 -WithSimulator

# 2. Surveiller les logs
tail -f logs/api.log
tail -f logs/streaming.log
tail -f logs/simulator.log

# 3. Tester
python tests/test_integration.py

# 4. ArrÃªter proprement
.\stop_pipeline.ps1
```

### RedÃ©marrage propre
```bash
# ArrÃªt avec nettoyage
.\stop_pipeline.ps1 -CleanData

# RedÃ©marrage
.\start_pipeline.ps1 -CleanStart -WithSimulator
```

---

## ğŸ“ Structure des donnÃ©es

```
data_lake/
â”œâ”€â”€ raw/                    # DonnÃ©es brutes IoT
â”‚   â””â”€â”€ iot_measurements/
â”œâ”€â”€ bronze/                 # DonnÃ©es nettoyÃ©es
â”‚   â”œâ”€â”€ iot_aggregations/   # AgrÃ©gations 5min
â”‚   â”œâ”€â”€ iot_alerts/         # Toutes alertes
â”‚   â””â”€â”€ device_status/      # Statut dispositifs
â””â”€â”€ silver/                 # DonnÃ©es enrichies
    â””â”€â”€ critical_alerts/    # Alertes critiques
```

---

## ğŸš¨ Alertes automatiques

Le systÃ¨me gÃ©nÃ¨re automatiquement des alertes pour :

| Condition | Seuil | GravitÃ© |
|-----------|-------|---------|
| **SpO2 critique** | < 90% | ğŸ”´ CRITICAL |
| **FrÃ©quence cardiaque** | < 50 ou > 150 bpm | ğŸ”´ CRITICAL |
| **FiÃ¨vre Ã©levÃ©e** | > 39Â°C | ğŸŸ  HIGH |
| **Crise drÃ©panocytaire** | SpO2 < 92% + TÂ° > 38Â°C | ğŸ”´ CRITICAL |

---

## ğŸ”§ Configuration

### Seuils mÃ©dicaux (config/.env)
```env
CRITICAL_SPO2_THRESHOLD=90
CRITICAL_HEART_RATE_MIN=50
CRITICAL_HEART_RATE_MAX=150
FEVER_THRESHOLD=38.0
```

### Simulateur
```env
SIMULATOR_PATIENTS_COUNT=5
SIMULATOR_INTERVAL_SECONDS=60
SIMULATOR_DURATION_MINUTES=30
```

---

## ğŸ“ˆ Monitoring en temps rÃ©el

### Dashboard Streamlit
```bash
# Lancer le dashboard
streamlit run monitoring/realtime_dashboard.py

# AccÃ¨s: http://localhost:8501
```

**FonctionnalitÃ©s :**
- âœ… Graphiques temps rÃ©el SpO2/FC
- ğŸš¨ Alertes par gravitÃ©
- ğŸ‘¥ Ã‰tat patients actifs
- ğŸ“Š MÃ©triques qualitÃ© signal

---

## ğŸ§ª Tests et validation

### Tests d'intÃ©gration
```bash
# Tests complets
python tests/test_integration.py

# Test de charge
pytest tests/test_integration.py::test_11_load_test -v
```

### Test manuel API
```bash
# Envoyer une mesure test
curl -X POST http://localhost:8001/iot/measurements \
  -H "Content-Type: application/json" \
  -d '{
    "device_id": "test-device",
    "patient_id": "test-patient",
    "timestamp": "2025-01-18T10:00:00",
    "measurements": {
      "freq_card": 75,
      "spo2_pct": 98.5,
      "temp_corp": 36.8
    }
  }'
```

---

## ğŸ” Debugging

### Logs importants
```bash
# API
tail -f logs/api.log

# Streaming (erreurs critiques)
tail -f logs/streaming.log

# Kafka (connexions)
docker logs kidjamo-kafka

# Simulateur (donnÃ©es gÃ©nÃ©rÃ©es)
tail -f logs/simulator.log
```

### Commandes de diagnostic
```bash
# VÃ©rifier topics Kafka
docker exec kidjamo-kafka kafka-topics --bootstrap-server localhost:9092 --list

# Voir messages en temps rÃ©el
docker exec kidjamo-kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic kidjamo-iot-measurements --from-beginning

# Ã‰tat des containers
docker ps
```

---

## âš ï¸ RÃ©solution de problÃ¨mes

### ProblÃ¨me: API non accessible
```bash
# VÃ©rifier le port
netstat -an | findstr 8001

# RedÃ©marrer
.\stop_pipeline.ps1
.\start_pipeline.ps1
```

### ProblÃ¨me: Kafka ne dÃ©marre pas
```bash
# Nettoyer volumes Docker
docker-compose -f kafka/docker-compose.yml down -v
docker system prune -f

# RedÃ©marrer
.\start_pipeline.ps1
```

### ProblÃ¨me: Streaming n'Ã©crit pas
```bash
# VÃ©rifier checkpoints
ls checkpoints/

# Nettoyer et redÃ©marrer
.\stop_pipeline.ps1 -CleanData
.\start_pipeline.ps1 -CleanStart
```

---

## ğŸ¯ Prochaines Ã©tapes

1. **IntÃ©gration avec votre DB** : Remplacer le data lake local par PostgreSQL
2. **Alertes temps rÃ©el** : IntÃ©grer avec votre systÃ¨me d'alertes
3. **Authentification** : Ajouter JWT/OAuth pour production
4. **Monitoring avancÃ©** : MÃ©triques Prometheus/Grafana
5. **Haute disponibilitÃ©** : Cluster Kafka multi-noeuds

---

## ğŸ“ Support

En cas de problÃ¨me :
1. Consulter les logs : `logs/`
2. VÃ©rifier la santÃ© : http://localhost:8001/health
3. Relancer les tests : `python tests/test_integration.py`
4. RedÃ©marrage propre : `stop_pipeline.ps1 -CleanData && start_pipeline.ps1 -CleanStart`
