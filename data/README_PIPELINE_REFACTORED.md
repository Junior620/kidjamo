# ğŸ¥ Pipeline d'Ingestion IoT MÃ©dical - Version RefactorisÃ©e

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Apache Spark 3.5+](https://img.shields.io/badge/spark-3.5+-orange.svg)](https://spark.apache.org/)
[![Code Style: PEP8](https://img.shields.io/badge/code%20style-PEP8-green.svg)](https://www.python.org/dev/peps/pep-0008/)
[![Medical Grade](https://img.shields.io/badge/medical-grade-red.svg)](https://www.fda.gov/)

## ğŸ“‹ Vue d'Ensemble

Pipeline d'ingestion temps rÃ©el pour donnÃ©es IoT mÃ©dicales avec architecture **Medallion** (RAW â†’ BRONZE â†’ SILVER â†’ GOLD) et conformitÃ© RGPD. Version entiÃ¨rement refactorisÃ©e avec documentation mÃ©dicale exhaustive, structure modulaire et gestion d'erreurs robuste.

### ğŸ¯ Objectifs MÃ©tier
- **Monitoring temps rÃ©el** : Surveillance continue des signes vitaux
- **DÃ©tection d'alertes** : Identification automatique des situations critiques
- **ConformitÃ© RGPD** : Pseudonymisation sÃ©curisÃ©e des donnÃ©es patients
- **Analytics mÃ©dicaux** : Features ML pour prÃ©diction et dÃ©tection d'anomalies

## ğŸ—ï¸ Architecture du Pipeline

```mermaid
graph TB
    A[Landing Zone<br/>CSV Files] --> B[01_to_raw.py<br/>RAW Layer]
    B --> C[02_raw_to_bronze.py<br/>BRONZE Layer]
    C --> D[03_bronze_to_silver.py<br/>SILVER Layer]
    D --> E[04_silver_to_gold.py<br/>GOLD Layer]
    
    B -.-> F[Quarantine<br/>Invalid Data]
    E --> G[BI Dashboard]
    E --> H[ML Features]
    E --> I[Real-time Alerts]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#fce4ec
    style D fill:#f3e5f5
    style E fill:#fff8e1
    style F fill:#ffebee
```

## ğŸ“ Structure du Projet

```
data/
â”œâ”€â”€ ğŸ“ jobs/                          # Scripts de transformation
â”‚   â”œâ”€â”€ 01_to_raw.py                 # RAW: Ingestion brute
â”‚   â”œâ”€â”€ 02_raw_to_bronze.py          # BRONZE: Nettoyage & validation
â”‚   â”œâ”€â”€ 03_bronze_to_silver.py       # SILVER: Enrichissement mÃ©dical
â”‚   â””â”€â”€ 04_silver_to_gold.py         # GOLD: AgrÃ©gations & ML
â”œâ”€â”€ ğŸ“ pipelines/                     # Orchestration
â”‚   â””â”€â”€ run_pipeline.py              # Script principal d'exÃ©cution
â”œâ”€â”€ ğŸ“ lake/                          # Data Lake
â”‚   â”œâ”€â”€ ğŸ“‚ landing/                   # DonnÃ©es sources (CSV)
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                       # DonnÃ©es brutes (Parquet)
â”‚   â”œâ”€â”€ ğŸ“‚ bronze/                    # DonnÃ©es nettoyÃ©es
â”‚   â”œâ”€â”€ ğŸ“‚ silver/                    # DonnÃ©es enrichies
â”‚   â”œâ”€â”€ ğŸ“‚ gold/                      # DonnÃ©es analytics
â”‚   â””â”€â”€ ğŸ“‚ quarantine/                # DonnÃ©es invalides
â””â”€â”€ ğŸ“ config/                        # Configuration
    â”œâ”€â”€ environment.py                # Gestion environnement
    â”œâ”€â”€ medical_thresholds.json       # Seuils mÃ©dicaux
    â””â”€â”€ settings.yaml                 # ParamÃ¨tres globaux
```

## ğŸš€ Installation et Configuration

### PrÃ©requis SystÃ¨me
```bash
# Java 8+ (requis pour Spark)
java -version

# Python 3.8+
python --version

# Apache Spark 3.5+
# TÃ©lÃ©charger depuis: https://spark.apache.org/downloads.html
```

### Configuration Spark Windows
```powershell
# Variables d'environnement
$env:JAVA_HOME = "C:\Path\To\Java\jdk-17"
$env:SPARK_HOME = "C:\spark-3.5.5-bin-hadoop3\spark-3.5.5-bin-hadoop3"
$env:PATH += ";$env:SPARK_HOME\bin"

# VÃ©rification installation
spark-submit --version
```

### Installation DÃ©pendances
```bash
# Installation requirements
pip install pyspark==3.5.5
pip install pandas>=1.5.0
pip install boto3>=1.26.0  # Pour mode cloud

# Configuration PYTHONPATH (automatique via run_pipeline.py)
```

## ğŸƒâ€â™‚ï¸ ExÃ©cution du Pipeline

### DÃ©marrage Rapide
```bash
# Navigation vers le rÃ©pertoire pipelines
cd D:\kidjamo-workspace\data\pipelines

# ExÃ©cution complÃ¨te du pipeline
python run_pipeline.py
```

### Mode DÃ©taillÃ©
```bash
# Le pipeline s'exÃ©cute automatiquement dans l'ordre:
# 1. ğŸ“¥ Landing â†’ RAW (Ingestion brute)
# 2. ğŸ§¹ RAW â†’ BRONZE (Nettoyage & validation)
# 3. âš•ï¸ BRONZE â†’ SILVER (Enrichissement mÃ©dical)
# 4. ğŸ“Š SILVER â†’ GOLD (AgrÃ©gations & ML)

# Avec gestion d'erreurs interactive:
# - Continuation optionnelle sur Ã©chec d'Ã©tape
# - Logs en temps rÃ©el avec mÃ©triques
# - RÃ©sumÃ© final de performance
```

## ğŸ“Š Couches du Data Lake

### ğŸ”µ RAW Layer (`01_to_raw.py`)
**RÃ´le**: Ingestion des donnÃ©es IoT brutes sans transformation mÃ©tier.

**FonctionnalitÃ©s**:
- âœ… Lecture CSV depuis `landing/` ou cloud (SQS/S3)
- âœ… Ajout mÃ©tadonnÃ©es techniques (`ingestion_ts`, `source_file`)
- âœ… Gestion robuste erreurs Windows/Spark
- âœ… Partitionnement par timestamp batch

**Sortie**: `raw/batch_ts={timestamp}/*.parquet`

### ğŸŸ¤ BRONZE Layer (`02_raw_to_bronze.py`)
**RÃ´le**: Nettoyage et validation avec contraintes mÃ©dicales.

**Transformations**:
- âœ… **Validation mÃ©dicale**: Seuils physiologiques par Ã¢ge
- âœ… **Pseudonymisation RGPD**: Hachage SHA-256 + salt
- âœ… **Normalisation colonnes**: SchÃ©ma standardisÃ©
- âœ… **DÃ©duplication**: ClÃ©s mÃ©tier temporelles
- âœ… **Quarantaine**: DonnÃ©es aberrantes isolÃ©es

**Contraintes MÃ©dicales**:
```python
MEDICAL_CONSTRAINTS = {
    "heart_rate_bpm": {"min": 40, "max": 200},     # FrÃ©quence cardiaque
    "SpO2": {"min": 70, "max": 100},               # Saturation oxygÃ¨ne
    "temperature_core_c": {"min": 35.0, "max": 42.0}, # TempÃ©rature corporelle
    "hydration_pct": {"min": 0, "max": 100},       # Niveau hydratation
    "respiratory_rate": {"min": 8, "max": 40},     # FrÃ©quence respiratoire
    "age": {"min": 0, "max": 120}                  # Ã‚ge patient
}
```

**Sortie**: `bronze/event_date=YYYY-MM-DD/*.parquet`

### ğŸ¥ˆ SILVER Layer (`03_bronze_to_silver.py`)
**RÃ´le**: Enrichissement mÃ©dical avec classification par groupes d'Ã¢ge.

**Classifications par Ã‚ge**:
- **G1** (0-1 an): Nourrissons - seuils critiques abaissÃ©s
- **G2** (1-5 ans): Jeunes enfants - surveillance renforcÃ©e
- **G3** (6-12 ans): Enfants - seuils intermÃ©diaires
- **G4** (13-17 ans): Adolescents - seuils adultes
- **G5** (18-59 ans): Adultes - seuils standards
- **G6** (60-80 ans): Seniors - vulnÃ©rabilitÃ© accrue

**Enrichissements**:
- âœ… **SpO2 Status**: Critical/Emergency/Alert/Vigilance/Normal
- âœ… **Temperature Status**: DiffÃ©rentiel nourrissons/seniors
- âœ… **Combinaisons Critiques**:
  - `C1_fever_hypoxia`: FiÃ¨vre + hypoxie (urgence vitale)
  - `C2_respiratory_distress`: DÃ©tresse respiratoire

**Sortie**: `silver/ingestion_date=YYYY-MM-DD/*.parquet`

### ğŸ¥‡ GOLD Layer (`04_silver_to_gold.py`)
**RÃ´le**: DonnÃ©es finales pour BI, ML et alerting temps rÃ©el.

**Produits de DonnÃ©es**:

#### ğŸ“ˆ Facts Daily (`gold/facts_daily/`)
AgrÃ©gations quotidiennes pour tableaux de bord:
```sql
SELECT ingestion_date,
       COUNT(*) as total_measurements,
       COUNT(DISTINCT patient_id) as unique_patients,
       AVG(heart_rate_bpm) as avg_heart_rate,
       AVG(temperature_core_c) as avg_temperature,
       MIN(SpO2) as min_spo2
FROM silver_data
GROUP BY ingestion_date
```

#### ğŸ¤– ML Features (`gold/features_ml/`)
CaractÃ©ristiques patients pour machine learning:
- **VariabilitÃ© FC**: DÃ©tection arythmies
- **Patterns temporels**: Heure moyenne de mesure
- **Profils patients**: Moyennes et Ã©carts-types
- **Features lag**: VariabilitÃ© entre mesures consÃ©cutives

#### ğŸš¨ Real-time Alerts (`gold/alerts_realtime/`)
Alertes critiques temps rÃ©el:
```python
ALERT_THRESHOLDS = {
    "HIGH_FEVER": 39.0,      # FiÃ¨vre critique
    "HYPOTHERMIA": 35.0,     # Hypothermie
    "TACHYCARDIA": 120,      # Rythme cardiaque Ã©levÃ©
    "BRADYCARDIA": 50,       # Rythme cardiaque bas
    "LOW_OXYGEN": 90         # Hypoxie critique
}
```

## âš™ï¸ Configuration AvancÃ©e

### Variables d'Environnement
```yaml
# config/settings.yaml
pipeline:
  mode: "local"  # local | cloud
  batch_size: 10
  local_data_path: "data/lake/landing"

aws:  # Mode cloud uniquement
  region: "eu-west-1"
  landing_bucket: "kidjamo-iot-landing"
  sqs_queue_url: "https://sqs.eu-west-1.amazonaws.com/xxx/iot-queue"
```

### Seuils MÃ©dicaux PersonnalisÃ©s
```json
// config/medical_thresholds.json
{
  "spo2_critical_threshold": {
    "nourrissons": 88,
    "enfants": 88,
    "adultes": 88
  },
  "temperature_emergency": {
    "nourrissons_seniors": 38.5,
    "autres": 39.0
  }
}
```

## ğŸ” Monitoring et Logs

### Logs d'ExÃ©cution
```bash
[2025-08-24 18:03:19] INFO: ğŸš€ DÃ‰MARRAGE DU PIPELINE D'INGESTION COMPLET
[2025-08-24 18:03:20] INFO: âœ… Spark trouvÃ© Ã : C:\spark-3.5.5\bin\spark-submit.cmd
[2025-08-24 18:03:20] INFO: âœ… DonnÃ©es trouvÃ©es dans landing: 1 fichier(s)
[2025-08-24 18:03:21] INFO: Ã‰TAPE 1/4: 01 - Landing to Raw
    INFO: CSV lu avec succÃ¨s, 100000 lignes dÃ©tectÃ©es
    SUCCESS: Wrote RAW -> raw/batch_ts=1724519001
[2025-08-24 18:03:45] INFO: âœ… Ã©tape 1 terminÃ©e avec succÃ¨s
```

### MÃ©triques de QualitÃ©
```bash
INFO: DonnÃ©es valides: 95847
INFO: DonnÃ©es en quarantaine: 4153
STATS: Data quality: 95.8%
```

## ğŸ§ª Tests et Validation

### Tests d'IntÃ©gritÃ©
```bash
# VÃ©rification schÃ©mas
python -m pytest tests/integration/test_schema_evolution.py

# Tests mÃ©dicaux
python -m pytest tests/unit/test_medical_thresholds.py

# Tests bout-en-bout
python -m pytest tests/scenario_tests/test_complete_pipeline.py
```

### GÃ©nÃ©ration DonnÃ©es Test
```bash
# CrÃ©ation jeu de donnÃ©es mÃ©dical rÃ©aliste
python generate_test_data.py --patients 1000 --days 30 --output data/lake/landing/
```

## ğŸš¨ Gestion d'Erreurs

### Continuation Interactive
```bash
Ã‰tape 2 a Ã©chouÃ©. Continuer avec l'Ã©tape suivante ? (y/N): y
```

### RÃ©solution ProblÃ¨mes Courants

#### âŒ "Spark n'est pas disponible"
```bash
# Solution: VÃ©rifier installation Spark
echo $SPARK_HOME
spark-submit --version

# Ajouter au PATH si nÃ©cessaire
export PATH=$SPARK_HOME/bin:$PATH
```

#### âŒ "No data found in bronze layer"
```bash
# VÃ©rifier donnÃ©es dans RAW
ls -la data/lake/raw/

# RÃ©exÃ©cuter Ã©tape prÃ©cÃ©dente
python data/jobs/01_to_raw.py
```

#### âŒ "Failed to write silver data"
```bash
# VÃ©rifier permissions rÃ©pertoire
chmod 755 data/lake/silver/

# VÃ©rifier espace disque
df -h
```

## ğŸ“ˆ Performance et Optimisations

### Optimisations Spark
```python
# Configuration automatique dans chaque job
.config("spark.sql.adaptive.enabled", "true")
.config("spark.sql.adaptive.coalescePartitions.enabled", "true")
.config("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
```

### Partitionnement Intelligent
- **RAW**: Par timestamp batch (`batch_ts=`)
- **BRONZE**: Par date Ã©vÃ©nement (`event_date=`)
- **SILVER**: Par date ingestion (`ingestion_date=`)
- **GOLD**: Par date et type de donnÃ©es

### MÃ©triques Performance
```bash
ğŸ RÃ‰SUMÃ‰ DU PIPELINE
DurÃ©e totale: 127.3 secondes
Jobs rÃ©ussis: 4
Jobs Ã©chouÃ©s: 0
PIPELINE TERMINÃ‰ AVEC SUCCÃˆS !
```

## ğŸ” SÃ©curitÃ© et ConformitÃ©

### ConformitÃ© RGPD
- âœ… **Pseudonymisation**: SHA-256 + salt pour `patient_id`
- âœ… **Minimisation**: Seules donnÃ©es mÃ©dicales nÃ©cessaires
- âœ… **TraÃ§abilitÃ©**: Logs d'accÃ¨s et transformations
- âœ… **Quarantaine**: Isolation donnÃ©es sensibles invalides

### SÃ©curitÃ© DonnÃ©es
- âœ… **Chiffrement au repos**: Parquet avec compression
- âœ… **Validation entrÃ©es**: Contraintes mÃ©dicales strictes
- âœ… **Audit trail**: Timestamps et mÃ©tadonnÃ©es complÃ¨tes

## ğŸ”„ Ã‰volutions et Roadmap

### âœ… Nouvelles FonctionnalitÃ©s (Version RefactorisÃ©e)
- [x] **Documentation mÃ©dicale exhaustive** avec protocoles par Ã¢ge
- [x] **Structure modulaire** avec 50+ fonctions helpers
- [x] **Type hints** Python pour robustesse
- [x] **Gestion d'erreurs** interactive avec continuation
- [x] **Optimisations Spark** pour performance
- [x] **ConformitÃ© PEP8** et coding standards

### ğŸš§ Prochaines Ã‰tapes
- [ ] **Streaming temps rÃ©el** avec Kafka/Kinesis
- [ ] **ML automatisÃ©** avec MLflow integration
- [ ] **API REST** pour requÃªtes gold layer
- [ ] **Dashboard Grafana** pour monitoring
- [ ] **Tests automatisÃ©s** CI/CD

### ğŸ“‹ IntÃ©grations Futures
- [ ] **DBT** pour transformations SQL
- [ ] **Great Expectations** pour qualitÃ© donnÃ©es
- [ ] **Apache Airflow** pour orchestration avancÃ©e
- [ ] **AWS Glue** pour catalogue de donnÃ©es

## ğŸ¤ Contribution

### Standards de Code
- **PEP8** compliance obligatoire
- **Type hints** sur toutes fonctions publiques
- **Docstrings** Google style en franÃ§ais
- **Tests unitaires** pour nouvelle fonctionnalitÃ©

### Structure Commits
```bash
feat(silver): ajouter classification seuils pÃ©diatriques
fix(bronze): corriger validation contraintes RGPD
docs(readme): mettre Ã  jour architecture pipeline
```

## ğŸ“ Support

### Contacts Ã‰quipe
- **Tech Lead**: Pipeline Architecture & Spark
- **Medical Expert**: Validation seuils physiologiques
- **Data Engineer**: Optimisations performance
- **DevOps**: Infrastructure & dÃ©ploiement

### Resources
- ğŸ“– [Documentation Spark 3.5](https://spark.apache.org/docs/3.5.0/)
- ğŸ¥ [Protocoles MÃ©dicaux IoT](docs/medical_protocols.md)
- ğŸ”’ [ConformitÃ© RGPD](docs/gdpr_compliance.md)
- ğŸš€ [Guide DÃ©ploiement](docs/deployment_guide.md)

---

**Version**: 2.0.0-refactored  
**DerniÃ¨re MAJ**: 24 AoÃ»t 2025  
**CompatibilitÃ©**: Python 3.8+, Spark 3.5+, Windows/Linux  
**Licence**: PropriÃ©taire - Usage mÃ©dical uniquement  

ğŸ¥ **Pipeline certifiÃ© pour usage mÃ©dical avec conformitÃ© RGPD** ğŸ”’
