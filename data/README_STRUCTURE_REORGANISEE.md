# ğŸ“ STRUCTURE REORGANISÃ‰E - DATA PIPELINE KIDJAMO

## ğŸ¯ Vue d'ensemble de la nouvelle organisation

Cette nouvelle structure dans `data/` centralise tous les composants du pipeline Kidjamo pour une meilleure organisation et maintenabilitÃ©.

## ğŸ“‚ Structure dÃ©taillÃ©e

```
data/
â”œâ”€â”€ configs/                    # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ medical_thresholds.json # Seuils mÃ©dicaux par gÃ©notype
â”‚   â”œâ”€â”€ settings.yaml          # Configuration gÃ©nÃ©rale
â”‚   â”œâ”€â”€ .env                   # Variables d'environnement
â”‚   â””â”€â”€ .env.template          # Template pour configuration
â”‚
â”œâ”€â”€ pipelines/                  # Orchestration et exÃ©cution
â”‚   â”œâ”€â”€ run_pipeline.py        # Point d'entrÃ©e principal
â”‚   â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”‚   â”œâ”€â”€ batch_etl/            # Traitement par batch
â”‚   â””â”€â”€ iot_streaming/        # Traitement temps rÃ©el
â”‚
â”œâ”€â”€ jobs/                      # Jobs de transformation
â”‚   â”œâ”€â”€ 01_to_raw.py          # Landing â†’ Raw
â”‚   â”œâ”€â”€ 02_raw_to_bronze.py   # Raw â†’ Bronze (validation)
â”‚   â”œâ”€â”€ 03_bronze_to_silver.py # Bronze â†’ Silver (enrichissement)
â”‚   â”œâ”€â”€ 04_silver_to_gold.py  # Silver â†’ Gold (agrÃ©gation)
â”‚   â”œâ”€â”€ metrics_exporter.py   # Export mÃ©triques qualitÃ©
â”‚   â””â”€â”€ offline_alerts_engine.py # Moteur d'alertes
â”‚
â”œâ”€â”€ lake/                      # Data Lake multicouche
â”‚   â”œâ”€â”€ landing/              # DonnÃ©es brutes IoT
â”‚   â”œâ”€â”€ raw/                  # DonnÃ©es organisÃ©es par date
â”‚   â”œâ”€â”€ bronze/               # DonnÃ©es validÃ©es
â”‚   â”œâ”€â”€ silver/               # DonnÃ©es enrichies mÃ©dicalement
â”‚   â””â”€â”€ gold/                 # DonnÃ©es agrÃ©gÃ©es pour dashboards
â”‚
â”œâ”€â”€ schemas/                   # DÃ©finitions de schÃ©mas
â”‚   â”œâ”€â”€ medical_iot_schema.py # SchÃ©ma principal IoT mÃ©dical
â”‚   â”œâ”€â”€ sql/                  # SchÃ©mas SQL (PostgreSQL)
â”‚   â””â”€â”€ nosql/                # SchÃ©mas NoSQL (si nÃ©cessaire)
â”‚
â”œâ”€â”€ security/                  # SÃ©curitÃ© et pseudonymisation
â”‚   â”œâ”€â”€ pseudonymization.py   # Pseudonymisation basique
â”‚   â””â”€â”€ pseudonymization_secure.py # Pseudonymisation avancÃ©e
â”‚
â”œâ”€â”€ test_data/                 # DonnÃ©es de test et simulation
â”‚   â”œâ”€â”€ clinical_events_100k.csv # Ã‰vÃ©nements cliniques simulÃ©s
â”‚   â”œâ”€â”€ clinical_synth_100k.csv # DonnÃ©es synthÃ©tiques
â”‚   â”œâ”€â”€ dataset_iot.py        # GÃ©nÃ©rateur IoT
â”‚   â””â”€â”€ generatecsv.py        # GÃ©nÃ©rateur CSV
â”‚
â”œâ”€â”€ quarantine/               # DonnÃ©es en quarantaine
â”‚   â””â”€â”€ ingestion_date=*/     # PartitionnÃ© par date
â”‚
â”œâ”€â”€ logs/                     # Logs d'exÃ©cution pipeline
â”œâ”€â”€ evidence/                 # Rapports de qualitÃ© et tests
â”œâ”€â”€ monitoring/               # MÃ©triques et surveillance
â”œâ”€â”€ migration/                # Scripts de migration DB
â”œâ”€â”€ dbt/                     # Transformations dbt (Data Build Tool)
â””â”€â”€ expectations/            # Tests de qualitÃ© (Great Expectations)
```

## ğŸ”§ Utilisation de la nouvelle structure

### **ExÃ©cution du pipeline principal**
```bash
cd data/pipelines
python run_pipeline.py
```

### **Configuration d'environnement**
1. Copier `.env.template` vers `.env`
2. Remplir les variables d'environnement
3. VÃ©rifier `configs/settings.yaml`

### **Tests et validation**
```bash
cd data/test_data
python dataset_iot.py --patients=100 --measurements=10000
```

## ğŸ¯ Avantages de cette rÃ©organisation

### **1. Centralisation**
- âœ… Tous les composants pipeline dans `data/`
- âœ… Configuration centralisÃ©e dans `configs/`
- âœ… Logs et monitoring unifiÃ©s

### **2. SÃ©paration des responsabilitÃ©s**
- âœ… `jobs/` : Logique de transformation
- âœ… `pipelines/` : Orchestration
- âœ… `lake/` : Stockage multicouche
- âœ… `security/` : Aspects sÃ©curitÃ©

### **3. Maintenance simplifiÃ©e**
- âœ… Structure claire et navigable
- âœ… Dependencies isolÃ©es par composant
- âœ… Tests et evidence sÃ©parÃ©s

### **4. Ã‰volutivitÃ©**
- âœ… FacilitÃ© d'ajout de nouveaux jobs
- âœ… Extension du data lake
- âœ… IntÃ©gration dbt et expectations

## ğŸš€ Prochaines Ã©tapes

1. **Validation** : Tester la nouvelle structure
2. **Configuration** : Adapter les chemins dans les scripts
3. **Documentation** : Mettre Ã  jour les README spÃ©cifiques
4. **CI/CD** : Adapter les pipelines de dÃ©ploiement

## ğŸ“ Support

Pour toute question sur cette nouvelle structure :
- Consulter les README dans chaque sous-dossier
- VÃ©rifier les logs dans `data/logs/`
- Examiner les mÃ©triques dans `data/evidence/`

---

**Date de rÃ©organisation :** 18 aoÃ»t 2025  
**Version :** 2.0  
**Statut :** âœ… Migration complÃ¨te rÃ©ussie
